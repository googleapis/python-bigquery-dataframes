{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2025 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get hands-on experience with Gemini-powered AI operator APIs in this notebook. We'll start with clear examples of API syntax, ensuring you understand how to use these operators. Then, we'll dive into a real-world application, showcasing their performance on a large dataset and providing key statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the BigFrames modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bigframes\n",
    "import bigframes.pandas as bpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the BigFrames version is at least `1.38.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging.version import Version\n",
    "\n",
    "assert Version(bigframes.__version__) >= Version(\"1.38.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set blob to true for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/shuowei/src/python-bigquery-dataframes/bigframes/_config/experiment_options.py:71: ApiDeprecationWarning: BigFrames Blob is in preview now. This flag is no longer needed.\n",
      "  warnings.warn(msg, category=bfe.ApiDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "bigframes.options.experiments.blob = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval of PDF URLs, text extraction, and chunking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/shuowei/src/python-bigquery-dataframes/bigframes/core/global_session.py:103: DefaultLocationWarning: No explicit location is set, so using location US for the session.\n",
      "  _global_session = bigframes.session.connect(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=262006177488-ka1m0ue4fptfmt9siejdd5lom7p39upa.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fpydata-google-auth.readthedocs.io%2Fen%2Flatest%2Foauth.html&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform&state=GE3CiB2iPQ32Mbcgug2H68pdMulb7j&prompt=consent&access_type=offline\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Project must be set to initialize BigQuery client. Try setting `bigframes.options.bigquery.project` first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chunks_df \u001b[38;5;241m=\u001b[39m \u001b[43mbpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_glob_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgs://garrettwu_bucket/pdfs/*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m chunks_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muri\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m bq_connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigframes-dev.us.bigframes-default-connection\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/src/python-bigquery-dataframes/bigframes/core/log_adapter.py:175\u001b[0m, in \u001b[0;36mmethod_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m _call_stack\u001b[38;5;241m.\u001b[39mappend(full_method_name)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mNotImplementedError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# Log method parameters that are implemented in pandas but either missing (TypeError)\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# or not fully supported (NotImplementedError) in BigFrames.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Logging is currently supported only when we can access the bqclient through\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# _block.session.bqclient.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_call_stack) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/src/python-bigquery-dataframes/bigframes/pandas/io/api.py:606\u001b[0m, in \u001b[0;36mfrom_glob_path\u001b[0;34m(path, connection, name)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_glob_path\u001b[39m(\n\u001b[1;32m    604\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, connection: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    605\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m bigframes\u001b[38;5;241m.\u001b[39mdataframe\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mglobal_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_default_session\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbigframes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_glob_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/python-bigquery-dataframes/bigframes/core/global_session.py:114\u001b[0m, in \u001b[0;36mwith_default_session\u001b[0;34m(func_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwith_default_session\u001b[39m(func_: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, _T], \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func_(\u001b[43mget_global_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/src/python-bigquery-dataframes/bigframes/core/global_session.py:103\u001b[0m, in \u001b[0;36mget_global_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _global_session_lock:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _global_session \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m         _global_session \u001b[38;5;241m=\u001b[39m \u001b[43mbigframes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbigframes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbigquery\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _global_session\n",
      "File \u001b[0;32m~/src/python-bigquery-dataframes/bigframes/session/__init__.py:2188\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m   2187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(context: Optional[bigquery_options\u001b[38;5;241m.\u001b[39mBigQueryOptions] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Session:\n\u001b[0;32m-> 2188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/python-bigquery-dataframes/bigframes/core/log_adapter.py:175\u001b[0m, in \u001b[0;36mmethod_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m _call_stack\u001b[38;5;241m.\u001b[39mappend(full_method_name)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mNotImplementedError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# Log method parameters that are implemented in pandas but either missing (TypeError)\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# or not fully supported (NotImplementedError) in BigFrames.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Logging is currently supported only when we can access the bqclient through\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# _block.session.bqclient.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_call_stack) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/src/python-bigquery-dataframes/bigframes/session/__init__.py:170\u001b[0m, in \u001b[0;36mSession.__init__\u001b[0;34m(self, context, clients_provider)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clients_provider \u001b[38;5;241m=\u001b[39m clients_provider\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clients_provider \u001b[38;5;241m=\u001b[39m \u001b[43mbigframes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClientsProvider\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_regional_endpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_regional_endpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapplication_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplication_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbq_kms_key_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bq_kms_key_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_endpoints_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_endpoints_override\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequests_transport_adapters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequests_transport_adapters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# TODO(shobs): Remove this logic after https://github.com/ibis-project/ibis/issues/8494\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# has been fixed. The ibis client changes the default query job config\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# so we are going to remember the current config and restore it after\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# the ibis client has been created\u001b[39;00m\n\u001b[1;32m    185\u001b[0m original_default_query_job_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbqclient\u001b[38;5;241m.\u001b[39mdefault_query_job_config\n",
      "File \u001b[0;32m~/src/python-bigquery-dataframes/bigframes/session/clients.py:107\u001b[0m, in \u001b[0;36mClientsProvider.__init__\u001b[0;34m(self, project, location, use_regional_endpoints, credentials, application_name, bq_kms_key_name, client_endpoints_override, requests_transport_adapters)\u001b[0m\n\u001b[1;32m    100\u001b[0m project \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    101\u001b[0m     project\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(_ENV_DEFAULT_PROJECT)\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m typing\u001b[38;5;241m.\u001b[39mcast(Optional[\u001b[38;5;28mstr\u001b[39m], credentials_project)\n\u001b[1;32m    104\u001b[0m )\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m project:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProject must be set to initialize BigQuery client. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry setting `bigframes.options.bigquery.project` first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m     )\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_application_name \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_get_application_names()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapplication_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m application_name\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m _get_application_names()\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project \u001b[38;5;241m=\u001b[39m project\n",
      "\u001b[0;31mValueError\u001b[0m: Project must be set to initialize BigQuery client. Try setting `bigframes.options.bigquery.project` first."
     ]
    }
   ],
   "source": [
    "chunks_df = bpd.from_glob_path(\"gs://garrettwu_bucket/pdfs/*\")\n",
    "chunks_df.columns = [\"uri\"]\n",
    "bq_connection = \"bigframes-dev.us.bigframes-default-connection\"\n",
    "chunks_df[\"chunk_text\"] = chunks_df[\"uri\"].blob.pdf_chunk(\n",
    "    connection=bq_connection, chunk_size=2000, overlap_size=200,\n",
    "    max_batching_rows=1\n",
    ")\n",
    "chunk_df_exploded = chunks_df[\"chunk_text\"].explode()\n",
    "chunk_df_exploded.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/shuowei/src/python-bigquery-dataframes/bigframes/core/global_session.py:114: DefaultLocationWarning: No explicit location is set, so using location US for the session.\n",
      "  return func(get_global_session(), *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Query job 4b6facd8-54f1-4a58-a2cb-db230bfc1388 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:4b6facd8-54f1-4a58-a2cb-db230bfc1388&page=queryresults\">Open Job</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Query job 9c194a18-b5ff-425f-9312-4dce3e21f4bf is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:9c194a18-b5ff-425f-9312-4dce3e21f4bf&page=queryresults\">Open Job</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chunks_df = bpd.from_glob_path(\"gs://shuowei_bucket/pdf/*\", name=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy files to genearte more inputs, now we have 1000 PDF files\n",
    "#copies = [chunks_df] * 20\n",
    "#chunks_df = bpd.concat(copies, ignore_index=True)\n",
    "#chunks_df = chunks_df.cache()\n",
    "chunks_df = chunks_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy files to genearte more inputs, now we have 10,000 PDF files\n",
    "copies = [chunks_df] * 100\n",
    "chunks_df = bpd.concat(copies, ignore_index=True)\n",
    "chunks_df = chunks_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy files again, now we have 100,000 PDF files\n",
    "copies = [chunks_df] * 10\n",
    "chunks_df = bpd.concat(copies, ignore_index=True)\n",
    "chunks_df = chunks_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Query job 58e48da6-87fb-4d17-97e0-d3d7e02ee58f is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:58e48da6-87fb-4d17-97e0-d3d7e02ee58f&page=queryresults\">Open Job</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/shuowei/src/python-bigquery-dataframes/bigframes/dataframe.py:4162: PreviewWarning: axis=1 scenario is in preview.\n",
      "  warnings.warn(msg, category=bfe.PreviewWarning)\n"
     ]
    }
   ],
   "source": [
    "bq_connection = \"bigframes-dev.us.bigframes-default-connection\"\n",
    "chunks_df[\"chunk_text\"] = chunks_df[\"pdf\"].blob.pdf_chunk(\n",
    "    connection=bq_connection)\n",
    "# notes: use connection is not necessary, we can use default connection.\n",
    "# However, in current stage, using a specfic conneciton will grant more quota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explode column for future processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df_exploded = chunks_df[\"chunk_text\"].explode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to a temporary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Query job c0c05fe3-c1cb-4d59-a1a1-c2a3d8582c94 is DONE. 49.0 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:c0c05fe3-c1cb-4d59-a1a1-c2a3d8582c94&page=queryresults\">Open Job</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chunk_df_exploded = chunk_df_exploded.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Query job 2145211c-d60f-45d2-acf8-c19c9176298f is DONE. 457.0 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:2145211c-d60f-45d2-acf8-c19c9176298f&page=queryresults\">Open Job</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Query job 77319c66-4155-48c2-af63-cf5a558e3cf5 is DONE. 455.2 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:77319c66-4155-48c2-af63-cf5a558e3cf5&page=queryresults\">Open Job</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    Integrating Reinforcement Learning, Action Mod...\n",
       "0    Benyamin)\n",
       "Preprint submitted to Artificial Int...\n",
       "0    classical, discrete, environments.\n",
       "Therefore, ...\n",
       "0    setting we consider in this work isoffline lea...\n",
       "0    more complex\n",
       "problems that required longer-ter...\n",
       "0    domain models for planning, and RL. We also pr...\n",
       "0    means that a planning domain defines parameter...\n",
       "0    which actions to perform in\n",
       "order to collect n...\n",
       "0    these\n",
       "assumptions, NSAM is guaranteed to retur...\n",
       "0    policy.\n",
       "Off-policy algorithms are algorithms t...\n",
       "0    the\n",
       "environment, mining resources, collecting ...\n",
       "0    must:\n",
       "1. Harvest at least one wood block from ...\n",
       "0    irreversible and the amount of resources in a ...\n",
       "0    created by observing an expert solve different...\n",
       "0    Moreover, most actions are TP TO actions, whic...\n",
       "0    our RL models. Moreover, our gym environment i...\n",
       "0    within that time limit,\n",
       "we consider the run as...\n",
       "0    length.\n",
       "4https://imitation.readthedocs.io\n",
       "5htt...\n",
       "0    planning lies in its capacity to generalize ac...\n",
       "0    for the simpler\n",
       "Craft Wooden Sword, BC is actu...\n",
       "0    the number of episodes\n",
       "in which the agent succ...\n",
       "0    policy using higher-quality examples. Figure 1...\n",
       "0    search\n",
       "processes may require higher computatio...\n",
       "0    right, (1, 1), move up, (1, 2), move right, (2...\n",
       "0    methodological tool to solve problems when pla...\n",
       "Name: chunk_text, dtype: string"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_df_exploded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of embeddings within BigFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigframes.ml import llm\n",
    "\n",
    "text_embedding_model = llm.TextEmbeddingGenerator(model_name=\"text-embedding-005\")\n",
    "embeddings_df = text_embedding_model.predict(chunk_df_exploded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Embedding table in Bigquery if not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_project_id = \"bigframes-dev\"\n",
    "test_dataset_id = \"shuowei_test_us\"\n",
    "test_table_id = \"pdf_chunk_embedding\"\n",
    "embedding_table_id = f\"{test_project_id}.{test_dataset_id}.{test_table_id}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save embedding into a BigQuery table for downstream processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df.to_gbq(destination_table=embedding_table_id,if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create vector search index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction of an index over these embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bigframes.bigquery as bbq\n",
    "bbq.create_vector_index(\n",
    "    table_id=embedding_table_id,\n",
    "    column_name=\"ml_generate_embedding_result\",\n",
    "    distance_type=\"cosine\",\n",
    "    index_type=\"ivf\",\n",
    "    ivf_options={\"num_lists\": 100},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search with pointers to the original pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution of vector search, with results linked back to the original PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the embedding of the words for search\n",
    "searched_words = [\"reinforce\"]\n",
    "searched_words_embeddings = text_embedding_model.predict(searched_words)\n",
    "embedding_result_column = \"ml_generate_embedding_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform vector search\n",
    "search_result = (\n",
    "    bbq.vector_search(\n",
    "        base_table=embedding_table_id,\n",
    "        column_to_search=embedding_result_column,\n",
    "        query=searched_words_embeddings,\n",
    "        query_column_to_search=embedding_result_column,\n",
    "        top_k=3,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
