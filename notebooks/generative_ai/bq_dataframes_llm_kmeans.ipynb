{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use BigQuery DataFrames to cluster and characterize complaints\n",
        "\n",
        "<table align=\"left\">\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/googleapis/python-bigquery-dataframes/tree/main/notebooks/generative_ai/bq_dataframes_llm_kmeans.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/googleapis/python-bigquery-dataframes/tree/main/notebooks/generative_ai/bq_dataframes_llm_kmeans.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/googleapis/python-bigquery-dataframes/tree/main/notebooks/generative_ai/bq_dataframes_llm_kmeans.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>                                                                                               \n",
        "</table>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n",
        "\n",
        "The goal of this notebook is to demonstrate a comment characterization algorithm for an online business. We will accomplish this using [Google's PaLM 2](https://ai.google/discover/palm2/) and [KMeans clustering](https://en.wikipedia.org/wiki/K-means_clustering) in three steps:\n",
        "\n",
        "1. Use PaLM2TextEmbeddingGenerator to [generate text embeddings](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings) for each of 10000 complaints sent to an online bank. If you're not familiar with what a text embedding is, it's a list of numbers that are like coordinates in an imaginary \"meaning space\" for sentences. (It's like [word embeddings](https://en.wikipedia.org/wiki/Word_embedding), but for more general text.) The important point for our purposes is that similar sentences are close to each other in this imaginary space.\n",
        "2. Use KMeans clustering to group together complaints whose text embeddings are near to eachother. This will give us sets of similar complaints, but we don't yet know _why_ these complaints are similar.\n",
        "3. Simply ask PaLM2TextGenerator in English what the difference is between the groups of complaints that we got. Thanks to the power of modern LLMs, the response might give us a very good idea of what these complaints are all about, but remember to [\"understand the limits of your dataset and model.\"](https://ai.google/responsibility/responsible-ai-practices/#:~:text=Understand%20the%20limitations%20of%20your%20dataset%20and%20model)\n",
        "\n",
        "We will tie these pieces together in Python using BigQuery DataFrames. [Click here](https://cloud.google.com/bigquery/docs/dataframes-quickstart) to learn more about BigQuery DataFrames!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset\n",
        "\n",
        "This notebook uses the [CFPB Consumer Complaint Database](https://console.cloud.google.com/marketplace/product/cfpb/complaint-database)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* BigQuery (compute)\n",
        "* BigQuery ML\n",
        "\n",
        "Learn about [BigQuery compute pricing](https://cloud.google.com/bigquery/pricing#analysis_pricing_models),\n",
        "and [BigQuery ML pricing](https://cloud.google.com/bigquery/pricing#bqml),\n",
        "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xckgWno6ouHY"
      },
      "source": [
        "## Step 1: Text embedding "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Project Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R7STCS8xB5d2"
      },
      "outputs": [],
      "source": [
        "import bigframes.pandas as bpd\n",
        "\n",
        "bpd.options.bigquery.project = \"bigframes-dev\"\n",
        "bpd.options.bigquery.location = \"us\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6FGschEowht"
      },
      "source": [
        "Data Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zDSwoBo1CU3G"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Query job ca9487e2-aac1-466d-a74c-bf1d414b7557 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:ca9487e2-aac1-466d-a74c-bf1d414b7557&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Query job 311d2026-8f38-4c76-a4eb-40f6a1810fd4 is DONE. 2.3 GB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:311d2026-8f38-4c76-a4eb-40f6a1810fd4&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "input_df = bpd.read_gbq(\"bigquery-public-data.cfpb_complaints.complaint_database\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tYDoaKgJChiq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Query job e9a7abc7-6fca-4a91-a68c-8feb3ac9b942 is DONE. 1.3 GB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:e9a7abc7-6fca-4a91-a68c-8feb3ac9b942&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Query job 4e0125c0-bd85-4449-a9b8-a68ea3407919 is DONE. 1.3 GB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:4e0125c0-bd85-4449-a9b8-a68ea3407919&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>consumer_complaint_narrative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Those Accounts Are Not mine, I never authorize...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Legal Department, This credit dispute is being...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Hello my name is XXXX XXXX, I have looked into...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>I HAVE REVIEWED MY CREDIT REPORT AND FOUND SOM...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>On my credit report these are not my items rep...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1 columns</p>\n",
              "</div>[5 rows x 1 columns in total]"
            ],
            "text/plain": [
              "                         consumer_complaint_narrative\n",
              "0   Those Accounts Are Not mine, I never authorize...\n",
              "11  Legal Department, This credit dispute is being...\n",
              "12  Hello my name is XXXX XXXX, I have looked into...\n",
              "15  I HAVE REVIEWED MY CREDIT REPORT AND FOUND SOM...\n",
              "16  On my credit report these are not my items rep...\n",
              "\n",
              "[5 rows x 1 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "issues_df = input_df[[\"consumer_complaint_narrative\"]].dropna()\n",
        "issues_df.head(n=5) # View the first five complaints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OltYSUEcsSOW"
      },
      "outputs": [],
      "source": [
        "# Choose 10,000 complaints randomly\n",
        "downsampled_issues_df = issues_df.sample(n=10000)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl2o-NYMoygb"
      },
      "source": [
        "Generate the text embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "li38q8FzDDMu"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Query job 5422de4b-789d-4430-ab73-3a238d7b5238 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:5422de4b-789d-4430-ab73-3a238d7b5238&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from bigframes.ml.llm import PaLM2TextEmbeddingGenerator\n",
        "\n",
        "model = PaLM2TextEmbeddingGenerator() # No connection id needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cOuSOQ5FDewD"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Query job 25ed7dd8-829b-4418-8f52-2ba9c5c51dec is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:25ed7dd8-829b-4418-8f52-2ba9c5c51dec&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Query job fde1380f-a308-440d-a9a3-a7c3db902e0a is DONE. 1.3 GB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:fde1380f-a308-440d-a9a3-a7c3db902e0a&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Query job c9bec87e-524a-4206-84d6-f9f87fc12e35 is DONE. 80.0 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:c9bec87e-524a-4206-84d6-f9f87fc12e35&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Query job 0ac2dee7-1c50-4b63-aa44-16ad43265c5d is DONE. 80.0 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:0ac2dee7-1c50-4b63-aa44-16ad43265c5d&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Query job bd615e5d-8153-45bf-a14e-e5997cbaa962 is DONE. 61.5 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:bd615e5d-8153-45bf-a14e-e5997cbaa962&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>[0.0032048337161540985, 0.018182063475251198, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>[-0.025085292756557465, -0.05178036540746689, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650</th>\n",
              "      <td>[0.0020703477784991264, -0.027994778007268906,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>[-0.009529653936624527, -0.03827650472521782, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1009</th>\n",
              "      <td>[0.0190849881619215, -0.026688968762755394, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1 columns</p>\n",
              "</div>[5 rows x 1 columns in total]"
            ],
            "text/plain": [
              "                                         text_embedding\n",
              "355   [0.0032048337161540985, 0.018182063475251198, ...\n",
              "414   [-0.025085292756557465, -0.05178036540746689, ...\n",
              "650   [0.0020703477784991264, -0.027994778007268906,...\n",
              "969   [-0.009529653936624527, -0.03827650472521782, ...\n",
              "1009  [0.0190849881619215, -0.026688968762755394, 0....\n",
              "\n",
              "[5 rows x 1 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Will take ~5 minutes to compute the embeddings\n",
        "predicted_embeddings = model.predict(downsampled_issues_df)\n",
        "# Notice the lists of numbers that are our text embeddings for each complaint\n",
        "predicted_embeddings.head() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H_etYfsEOFP"
      },
      "outputs": [],
      "source": [
        "# Join the complaints with their embeddings in the same DataFrame\n",
        "combined_df = downsampled_issues_df.join(predicted_embeddings)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OUZ3NNbzo1Tb"
      },
      "source": [
        "## Step 2: KMeans clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AhNTnEC5FRz2"
      },
      "outputs": [],
      "source": [
        "from bigframes.ml.cluster import KMeans\n",
        "\n",
        "cluster_model = KMeans(n_clusters=10) # We will divide our complaints into 10 groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6poSxh-fGJF7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Query job 803f2250-b38d-4215-8941-b668dc18c023 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:803f2250-b38d-4215-8941-b668dc18c023&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Query job 04fe13b0-d07c-4490-ace5-7602830538f4 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:04fe13b0-d07c-4490-ace5-7602830538f4&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Query job 3735b6fd-0c0c-4ad1-83b1-77c09e7c4c68 is DONE. 1.4 GB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:3735b6fd-0c0c-4ad1-83b1-77c09e7c4c68&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Query job 1c597324-756b-4c96-9520-966f839c3e14 is DONE. 80.0 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:1c597324-756b-4c96-9520-966f839c3e14&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Query job acc3f4ab-71e1-4e51-938d-a447db70dd73 is DONE. 80.0 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:acc3f4ab-71e1-4e51-938d-a447db70dd73&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Query job 1d11a4e3-7dd3-4619-bf46-f9d842abe83a is DONE. 160.0 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:1d11a4e3-7dd3-4619-bf46-f9d842abe83a&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CENTROID_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1009</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1 columns</p>\n",
              "</div>[5 rows x 1 columns in total]"
            ],
            "text/plain": [
              "      CENTROID_ID\n",
              "355             4\n",
              "414             2\n",
              "650             1\n",
              "969             5\n",
              "1009            5\n",
              "\n",
              "[5 rows x 1 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use KMeans clustering to calculate our groups. Will take ~5 minutes.\n",
        "cluster_model.fit(combined_df[[\"text_embedding\"]])\n",
        "clustered_result = cluster_model.predict(combined_df[[\"text_embedding\"]])\n",
        "# Notice the CENTROID_ID column, which is the ID number of the group that\n",
        "# each complaint belongs to.\n",
        "clustered_result.head(n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Join the group number to the complaints and their text embeddings\n",
        "combined_clustered_result = combined_df.join(clustered_result)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "21rNsFMHo8hO"
      },
      "source": [
        "## Step 3: Summarize the complaints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2E7wXM_jGqo6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Query job cf667104-32c3-4ca9-96ac-d044823096c4 is DONE. 1.3 GB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:cf667104-32c3-4ca9-96ac-d044823096c4&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Query job 8088b224-bf24-4cf8-9858-c5bb47c0d3ee is DONE. 1.3 GB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:8088b224-bf24-4cf8-9858-c5bb47c0d3ee&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Using bigframes, with syntax identical to pandas,\n",
        "# filter out the first and second groups\n",
        "cluster_1_result = combined_clustered_result[\n",
        "    combined_clustered_result[\"CENTROID_ID\"] == 1][[\"consumer_complaint_narrative\"]\n",
        "]\n",
        "cluster_1_result_pandas = cluster_1_result.head(5).to_pandas()\n",
        "\n",
        "cluster_2_result = combined_clustered_result[\n",
        "    combined_clustered_result[\"CENTROID_ID\"] == 2][[\"consumer_complaint_narrative\"]\n",
        "]\n",
        "cluster_2_result_pandas = cluster_2_result.head(5).to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZNDiueI9IP5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "comment list 1:\n",
            "1. I bought my home XX/XX/XXXX for the amount of {$220000.00}. The home was appraised closing with a value of {$260000.00} at closing. When purchasing the home I did not provide a downpayment in the amount of 20 % of the home value, therefore I had to purchase private mortgage insurance ( P.M.I. ) on the home until 20 % of the home value was paid off. 20 % of {$260000.00} is {$53000.00}. This means I would have to owe ( $ XXXX- {$53000.00} ) {$210000.00} or less for the P.M.I. to be taken off of my monthly mortgage payments. According to law, the lender should take the P.M.I. off of my loan once the 20 % is met. At the time of closing my borrower did not provide me a PMI disclosure form to identify when the 20 % mark would be met. \n",
            "\n",
            "When closing on my home my loan was thru XXXX XXXX XXXX, for the past 5+ years my loan was taken over by Wells Fargo Home Mortgage and they are my current lenders. I have never missed or been late on a mortgage payment. \n",
            "\n",
            "In XX/XX/XXXX I reached the 20 % mark on the value of my home. Starting XX/XX/XXXX I have owed {$210000.00} or less on my home. As of XX/XX/XXXX I owe {$190000.00}, this is far beyond owning 80 % or less of my home value. \n",
            "\n",
            "I have reached out to Wells Fargo to have the PMI removed from my mortgage payments, but they refuse. Wells Fargo has stated that I must pay off 22 % of the \" loan '' before PMI can be taken off, and that the 20 % is not based on the value of the home at closing. \n",
            "\n",
            "It was never identified to me at closing that the 20 % was based the \" value of the loan '' and not the appraised value of the home at closing. This information is new to me and in XX/XX/XXXX I do not believe this was the agreement at closing. I would like to receive some evidence that I agreed to an otherwise condition against having the PMI be based on the value of the home at closing.\n",
            "2. I paid my two months mortgage amount of {$3300.00} ( XX/XX/2020 ) and {$3300.00} ( XX/XX/2020 ) to my lender ( XXXX XXXX - XXXX XXXX ). Then I also received another payment notice from TIAA Bank that said my loan was sold to them on XX/XX/2020. I have not received any Goodbye Letter from my lender, nor did my Welcome Letter from TIAA Bank. I provided my bank statement for those two payments to TIAA Bank shows the proof of payments, and never got a reply from them. I called XXXX XXXX and request the Goodbye letter, which indicates - The servicing of your mortgage loan is being transferred, effective XX/XX/2020. My complaint is the lack of information when the loan was transferred to one servicer to another. I am not properly informed my loan had been transferred. As a result, payments made to either the prior or current servicer around the time of the transfer were not applied to the account.\n",
            "3. On XX/XX/XXXX I called Quicken Loans to inquire about Refinancing options. I was in the process of an application with another lender and I was unhappy with their terms, etc. I spoke with XXXX XXXX of Quicken who convinced me to move my business over to Quicken. He stated the refinance would only take approx 30 days to complete. I did so that day and within 2 days had completed all paperwork requirements etc. I was now waiting for the appraisal to take place. Weeks went by and i never heard from anyone. I placed numerous calls, emails, chats to different people and was told that it was a delay due to \" volume ''. Finally, on XXXX the appraisal was completed. Again, silence for days/weeks afterwards. On XXXX I called and spoke with a rep who said the appraisal was \" in hand '' and Quicken and the appraiser have been in constant contact discussing some issues in the report, specifically regarding a \" capping of a water line '' and a possible \" apartment ''. I asked to see the report and she said it will post shortly to my account. It never posted. I again never heard from anyone at Quicken. I called, I emailed, I chatted with Quicken and was repeatedly told the report is not yet finalized. They also told me there were NO ISSUES regarding the appraisal -- the delay was purely due to volume. I explained that someone already told me of a possible issue and every person i spoke to denied this fact. Finally, on XX/XX/XXXX the \" dashboard '' for my account with Quicken was updated ( still no word from anyone and no copy of my appraisal was provided ) and it showed a drastic change to my refinance # s. My loan amount was reduced by {$30000.00} approx. and my debt to be paid off with the loan were removed. The entire formulation of the refinance was changed without any explanation or notice to me. I called my banker, I called customer solutions, etc. again and now i was told, \" Oh, the appraisal came in low '' So, bottom line is ... .you need {$13000.00} to {$15000.00} cash to settle this loan at the new rate. '' Again, no mention of the issue with the apartment. I asked for a copy of the appraisal and was finally sent a copy on XXXX. My issue with Quicken is : 1. They took 4 weeks to send an appraiser. 2. They had the results of the appraisal since early XXXX but repeatedly lied to me stating the appraisal had never been seen and was still being created. They strung me along for 8 weeks. I lost my other offer. They \" low balled '' my appraisal with XXXX in order to \" kill my deal '' for reasons other than the apartment conditions. They did not want to take on this loan but they knew they had strung me along for 8 weeks and figured the low appraisal would be their ticket out. I have a XXXX bed XXXX bath home and comps are all running in my immediate area for $ XXXX and they came back with an appraisal of {$400000.00}. Absurd. My kitchen and bathrooms were completely remodeled. {$400000.00} is a ridiculous appraisal and they know it. I sent them XXXX recent comps in my immediate neighborhood of $ XXXX sold values. When i did that, then and only then did they say, \" well ... you have to satisfy the conditions of the appraisal also. Those conditions are ... rip out the cabinets, sink etc in lower level or obtain a C/O/permit. \" Quicken had no intention of closing on this refinance ... they knew that was the course they were taking in early XXXX but they chose to string me along for a total of 8 weeks. It was ONLY due to my insistence on XX/XX/XXXX that this issue be addressed that they finally showed me a copy of the appraisal. I lost my other connection/relationship and find their practices unfair and self-serving. No one should have to go through this again, hopefully. I have copies of emails, chats, etc. showing how they lied to me continuously and misled me. I hope this casts a shadow on their reputation and makes them reconsider their business practices. Thanks\n",
            "4. Hi, I was looking into buying a home. I never took the step to get pre qualified for a loan because it obviously needed more thought. I would look on XXXX everyday to see if houses were within my budget and eventually I started dealing with a real estate agent. Before she can look for homes she suggested that I get prequalified for a loan with an associate of hers in that field. I started the application but never finished it just because I was unsure if I would get approved or not then come to find out the house I was interested in ( XXXX ) had gotten sold so I let the idea of buying a house go a bit. I get a message from the loan officer that she ran my credit she has a couple questions about my income. I call back instantly wondering why did you run my credit without authorization theres a reason I never finished the application I did not want a hard inquiry and I had kind of backed off. She proceeded to ask do I want to know the results and annoyed obviously I asked well you ran my credit without permission im going to have a hard inquiry on my report now. She never gave me an explanation on WHY she ran my credit & now I lost a lot of points that I work hard for. I really want a solution to this problem because its not right to just run someones credit after the application is obviously not completed.\n",
            "5. I called on  XXXX   XXXX  requesting options on how to lower my principal amount. Unfortunately, I went into  Income dri ven Repayment program but instant of seeing a deduction of my principal, I see an increase over and over. The amount stills $  XXXX  since my graduation date back in   XXXX  . I mentioned that I worked for th e    XXXX   XXXX   XXXX   for 8 years if any portion of my loan could be forgive, they said no. Their option was to add more funds to my payments, which is totally ridiculously. Specially, now that I found out that my position will be eliminated in  XXXX   XXXX . Therefore, I will be unemployed after  XXXX   XXXX . It saddens my  heart that  something that I did to better myself, pursue an  XXXX  had cost me such of major debt and nobody is willing to help me. I did n't said that I was n't going to pay, I was seeking for assistance on how to lowered my principal and eventually payoff my debt. The education format from  XXXX  is heavily criticized, all funds paid and was n't top notch education!! Please help me understand why I could n't get any positive outcome fro m Navient.\n",
            "\n",
            "comment list 2:\n",
            "1. There is a charge on my credit report from HSBC that is over 10 years old. I have contacted the company and asked for the contract showing this is a valid debit and they have refused to send what I am asking. All they have sent me is a statement telling me this is a valid date, but no signed contract.\n",
            "2. Convergent Outsourcing is attempting to collect on an account that I have no knowledge of and that I have already reported to the credit bureaus as not being my account. I have contacted them asking that they validate not verify the debt that they are attempting to collect from me and derogatorily reporting on my credit reports. I specifically requested signed contracts or other supporting documentation, the only thing that I keep receiving back is that the account has been verified which does not prove that I am obligated to pay them anything which is not the truth because this account does not belong to me. They have reported delinquent information to the credit bureaus since XX/XX/2016 I am asking be deleted.\n",
            "3. Hi I am submitting this XXXX XXXX XXXX this isn't any influence and this is not a third party. XXXX has low and unfair credit number for me in their report. I have complained. The problem has not been resolved. my fico has me at a credit score over 719XXXX has me at a score around 590. That is a huge difference. XXXX paints me as a XXXX. my fico say I have good credit. What the heck is going on here. i have almost no debt and my identity was stolen causing my score to drop XXXX i made this clear for 60 days straight with XXXX  i spoke to a representative agent name XXXX and XXXX and XXXX from the fraud department I prefer to speak to a XXXX rept but they refused they had me on mute for 4 hours which was hurtful I have a perfect repayment record. I have very low credit utilization. I have three negative credit items outstanding debt now. I have modest but ok income. Social Security. Something is wrong with XXXX. I do not understand why they are abusing consumers .This was a fist step towards attempting resolution. They kept lying telling me they disputed n its not reporting but it keep reporting this inaccurate information without my authorization. They refused or were unable to verify n remove the inquiries and its been 60days n they record the calls n admitted they had my police report n ftc and affidavit That was after attempting to contact XXXX more than 21 times. XXXX is an abusive company. They are supposed to be protecting consumers. They need to be reigned in. they are causing me severe XXXX and stopping me from getting this job offer XXXX now XXXX XXXX  XXXX cant provide to my XXXXXXXX XXXX XXXX daughter PLEASE HELP ME PLEASE XXXX XXXX  now.with no help.\n",
            "4. On XX/XX/XXXX, I recieved a report from XXXX XXXX XXXX XXXX XXXX, XXXX, MD XXXX XXXX ) XXXX, which indicated a closed account from XXXX  XXXX auto opened in XX/XX/XXXX, but was removed from my credit report in XXXX, due to being older than 7 years I recieved this credit alert from equifax, XXXX in XXXX that it fell off my credit report. on XX/XX/XXXX, I see it's been placed back on my credit report in XX/XX/XXXX by this agency and when I logged in to see Equifax credit report and look at my closed accounts, XXXX  XXXX shows ( Closed Account ) but it's there to view and it's been there for XXXX  year and XXXX  months, so my complaint is why is it there it shouldn't even show, for XXXX  years XXXX months they've had this on my report, I want it removed because eventhough these account show closed, they are still sending out old information that should not be reported. This is causing me to pay more and keeping my credit score down, please enforce this and make them remove any and all closed accounts. Their disclaimer even states that these accounts are removed after 7 years, it's been XXXX, they should remove all of those closed accounts that way this will not happen again, and I'm asking that they be sued because this keeps certain groups of people credit scores down and that's discrimination, its also fraudulent because on one hand their telling us that this information is not being reported it's closed yet it shows up, so they are lying.\n",
            "5. -In XX/XX/XXXX, I was sent a notice to my address in Michigan by XXXX XXXX XXXX XXXX XXXX that my debt ( collected after having to live off my card due to house and joblessness ) had been sold to Portfolio Recovery Associates , LLC for {$2200.00}. As I had already moved to Florida, this letter was not forwarded to me in a timely manner. At this time, it showed up on my credit report as a collection debt. \n",
            "\n",
            "-Once I had obtained the supplemental information provided by Portfolio Recovery Associates LLC as proof of veracity of claim after disputing the collection, I was able to see the aforementioned notice, as well as a statement from Portfolio Recovery Associates containing my account number, the ( now corrected after an updated credit report request by them ) Florida address it was sent to, amount owed, contact information, etc. When I contacted Portfolio Recovery Associates, I was told they could not give me any further information because it had been transferred to be litigated. \n",
            "\n",
            "-Three years to the day XXXX XX/XX/XXXX XXXX and two states later, apparently a lawsuit was filed against me in an attempt to collect the debt. I was never served a summons. Once I found out about and looked up the case, I saw they had the correct address but an incorrect name, one that was corrected with the credit bureaus two months after said debt was sold to PRA. Thus, the notice of 'summons returned served ' in the court review is incorrect. Once I learned of the suit, I submitted the necessary paper work on my behalf. After that, I didn't hear from them, nor did an updated search return anything. \n",
            "\n",
            "-In XXXX of this year, I received a notice from the XXXX XXXX XXXX XXXX XXXX stating that the case was to be closed in a month due to lack of prosecution if no action takes place before then. Just before that dead line, the attorneys for PRA XXXX XXXX XXXX XXXX XXXX filed a motion to transfer the case to XXXX XXXX, citing that this was where they ( in fact did not ) serve the original summons. Once this was granted, they received a letter from the Clerk of Court stating they had 30 days to pay the transfer fees or the case would be dismissed. Two days before that due date, they submitted payment at the last minute. As of yet, I have not seen nor received anything from the XXXX XXXX XXXX XXXX regarding the matter.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Build plain-text prompts to send to PaLM 2. Use only 5 complaints from each group.\n",
        "prompt1 = 'comment list 1:\\n'\n",
        "for i in range(5):\n",
        "    prompt1 += str(i + 1) + '. ' + \\\n",
        "        cluster_1_result_pandas[\"consumer_complaint_narrative\"].iloc[i] + '\\n'\n",
        "\n",
        "prompt2 = 'comment list 2:\\n'\n",
        "for i in range(5):\n",
        "    prompt2 += str(i + 1) + '. ' + \\\n",
        "        cluster_2_result_pandas[\"consumer_complaint_narrative\"].iloc[i] + '\\n'\n",
        "\n",
        "print(prompt1)\n",
        "print(prompt2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BfHGJLirzSvH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please highlight the most obvious difference betweenthe two lists of comments:\n",
            "comment list 1:\n",
            "1. I bought my home XX/XX/XXXX for the amount of {$220000.00}. The home was appraised closing with a value of {$260000.00} at closing. When purchasing the home I did not provide a downpayment in the amount of 20 % of the home value, therefore I had to purchase private mortgage insurance ( P.M.I. ) on the home until 20 % of the home value was paid off. 20 % of {$260000.00} is {$53000.00}. This means I would have to owe ( $ XXXX- {$53000.00} ) {$210000.00} or less for the P.M.I. to be taken off of my monthly mortgage payments. According to law, the lender should take the P.M.I. off of my loan once the 20 % is met. At the time of closing my borrower did not provide me a PMI disclosure form to identify when the 20 % mark would be met. \n",
            "\n",
            "When closing on my home my loan was thru XXXX XXXX XXXX, for the past 5+ years my loan was taken over by Wells Fargo Home Mortgage and they are my current lenders. I have never missed or been late on a mortgage payment. \n",
            "\n",
            "In XX/XX/XXXX I reached the 20 % mark on the value of my home. Starting XX/XX/XXXX I have owed {$210000.00} or less on my home. As of XX/XX/XXXX I owe {$190000.00}, this is far beyond owning 80 % or less of my home value. \n",
            "\n",
            "I have reached out to Wells Fargo to have the PMI removed from my mortgage payments, but they refuse. Wells Fargo has stated that I must pay off 22 % of the \" loan '' before PMI can be taken off, and that the 20 % is not based on the value of the home at closing. \n",
            "\n",
            "It was never identified to me at closing that the 20 % was based the \" value of the loan '' and not the appraised value of the home at closing. This information is new to me and in XX/XX/XXXX I do not believe this was the agreement at closing. I would like to receive some evidence that I agreed to an otherwise condition against having the PMI be based on the value of the home at closing.\n",
            "2. I paid my two months mortgage amount of {$3300.00} ( XX/XX/2020 ) and {$3300.00} ( XX/XX/2020 ) to my lender ( XXXX XXXX - XXXX XXXX ). Then I also received another payment notice from TIAA Bank that said my loan was sold to them on XX/XX/2020. I have not received any Goodbye Letter from my lender, nor did my Welcome Letter from TIAA Bank. I provided my bank statement for those two payments to TIAA Bank shows the proof of payments, and never got a reply from them. I called XXXX XXXX and request the Goodbye letter, which indicates - The servicing of your mortgage loan is being transferred, effective XX/XX/2020. My complaint is the lack of information when the loan was transferred to one servicer to another. I am not properly informed my loan had been transferred. As a result, payments made to either the prior or current servicer around the time of the transfer were not applied to the account.\n",
            "3. On XX/XX/XXXX I called Quicken Loans to inquire about Refinancing options. I was in the process of an application with another lender and I was unhappy with their terms, etc. I spoke with XXXX XXXX of Quicken who convinced me to move my business over to Quicken. He stated the refinance would only take approx 30 days to complete. I did so that day and within 2 days had completed all paperwork requirements etc. I was now waiting for the appraisal to take place. Weeks went by and i never heard from anyone. I placed numerous calls, emails, chats to different people and was told that it was a delay due to \" volume ''. Finally, on XXXX the appraisal was completed. Again, silence for days/weeks afterwards. On XXXX I called and spoke with a rep who said the appraisal was \" in hand '' and Quicken and the appraiser have been in constant contact discussing some issues in the report, specifically regarding a \" capping of a water line '' and a possible \" apartment ''. I asked to see the report and she said it will post shortly to my account. It never posted. I again never heard from anyone at Quicken. I called, I emailed, I chatted with Quicken and was repeatedly told the report is not yet finalized. They also told me there were NO ISSUES regarding the appraisal -- the delay was purely due to volume. I explained that someone already told me of a possible issue and every person i spoke to denied this fact. Finally, on XX/XX/XXXX the \" dashboard '' for my account with Quicken was updated ( still no word from anyone and no copy of my appraisal was provided ) and it showed a drastic change to my refinance # s. My loan amount was reduced by {$30000.00} approx. and my debt to be paid off with the loan were removed. The entire formulation of the refinance was changed without any explanation or notice to me. I called my banker, I called customer solutions, etc. again and now i was told, \" Oh, the appraisal came in low '' So, bottom line is ... .you need {$13000.00} to {$15000.00} cash to settle this loan at the new rate. '' Again, no mention of the issue with the apartment. I asked for a copy of the appraisal and was finally sent a copy on XXXX. My issue with Quicken is : 1. They took 4 weeks to send an appraiser. 2. They had the results of the appraisal since early XXXX but repeatedly lied to me stating the appraisal had never been seen and was still being created. They strung me along for 8 weeks. I lost my other offer. They \" low balled '' my appraisal with XXXX in order to \" kill my deal '' for reasons other than the apartment conditions. They did not want to take on this loan but they knew they had strung me along for 8 weeks and figured the low appraisal would be their ticket out. I have a XXXX bed XXXX bath home and comps are all running in my immediate area for $ XXXX and they came back with an appraisal of {$400000.00}. Absurd. My kitchen and bathrooms were completely remodeled. {$400000.00} is a ridiculous appraisal and they know it. I sent them XXXX recent comps in my immediate neighborhood of $ XXXX sold values. When i did that, then and only then did they say, \" well ... you have to satisfy the conditions of the appraisal also. Those conditions are ... rip out the cabinets, sink etc in lower level or obtain a C/O/permit. \" Quicken had no intention of closing on this refinance ... they knew that was the course they were taking in early XXXX but they chose to string me along for a total of 8 weeks. It was ONLY due to my insistence on XX/XX/XXXX that this issue be addressed that they finally showed me a copy of the appraisal. I lost my other connection/relationship and find their practices unfair and self-serving. No one should have to go through this again, hopefully. I have copies of emails, chats, etc. showing how they lied to me continuously and misled me. I hope this casts a shadow on their reputation and makes them reconsider their business practices. Thanks\n",
            "4. Hi, I was looking into buying a home. I never took the step to get pre qualified for a loan because it obviously needed more thought. I would look on XXXX everyday to see if houses were within my budget and eventually I started dealing with a real estate agent. Before she can look for homes she suggested that I get prequalified for a loan with an associate of hers in that field. I started the application but never finished it just because I was unsure if I would get approved or not then come to find out the house I was interested in ( XXXX ) had gotten sold so I let the idea of buying a house go a bit. I get a message from the loan officer that she ran my credit she has a couple questions about my income. I call back instantly wondering why did you run my credit without authorization theres a reason I never finished the application I did not want a hard inquiry and I had kind of backed off. She proceeded to ask do I want to know the results and annoyed obviously I asked well you ran my credit without permission im going to have a hard inquiry on my report now. She never gave me an explanation on WHY she ran my credit & now I lost a lot of points that I work hard for. I really want a solution to this problem because its not right to just run someones credit after the application is obviously not completed.\n",
            "5. I called on  XXXX   XXXX  requesting options on how to lower my principal amount. Unfortunately, I went into  Income dri ven Repayment program but instant of seeing a deduction of my principal, I see an increase over and over. The amount stills $  XXXX  since my graduation date back in   XXXX  . I mentioned that I worked for th e    XXXX   XXXX   XXXX   for 8 years if any portion of my loan could be forgive, they said no. Their option was to add more funds to my payments, which is totally ridiculously. Specially, now that I found out that my position will be eliminated in  XXXX   XXXX . Therefore, I will be unemployed after  XXXX   XXXX . It saddens my  heart that  something that I did to better myself, pursue an  XXXX  had cost me such of major debt and nobody is willing to help me. I did n't said that I was n't going to pay, I was seeking for assistance on how to lowered my principal and eventually payoff my debt. The education format from  XXXX  is heavily criticized, all funds paid and was n't top notch education!! Please help me understand why I could n't get any positive outcome fro m Navient.\n",
            "comment list 2:\n",
            "1. There is a charge on my credit report from HSBC that is over 10 years old. I have contacted the company and asked for the contract showing this is a valid debit and they have refused to send what I am asking. All they have sent me is a statement telling me this is a valid date, but no signed contract.\n",
            "2. Convergent Outsourcing is attempting to collect on an account that I have no knowledge of and that I have already reported to the credit bureaus as not being my account. I have contacted them asking that they validate not verify the debt that they are attempting to collect from me and derogatorily reporting on my credit reports. I specifically requested signed contracts or other supporting documentation, the only thing that I keep receiving back is that the account has been verified which does not prove that I am obligated to pay them anything which is not the truth because this account does not belong to me. They have reported delinquent information to the credit bureaus since XX/XX/2016 I am asking be deleted.\n",
            "3. Hi I am submitting this XXXX XXXX XXXX this isn't any influence and this is not a third party. XXXX has low and unfair credit number for me in their report. I have complained. The problem has not been resolved. my fico has me at a credit score over 719XXXX has me at a score around 590. That is a huge difference. XXXX paints me as a XXXX. my fico say I have good credit. What the heck is going on here. i have almost no debt and my identity was stolen causing my score to drop XXXX i made this clear for 60 days straight with XXXX  i spoke to a representative agent name XXXX and XXXX and XXXX from the fraud department I prefer to speak to a XXXX rept but they refused they had me on mute for 4 hours which was hurtful I have a perfect repayment record. I have very low credit utilization. I have three negative credit items outstanding debt now. I have modest but ok income. Social Security. Something is wrong with XXXX. I do not understand why they are abusing consumers .This was a fist step towards attempting resolution. They kept lying telling me they disputed n its not reporting but it keep reporting this inaccurate information without my authorization. They refused or were unable to verify n remove the inquiries and its been 60days n they record the calls n admitted they had my police report n ftc and affidavit That was after attempting to contact XXXX more than 21 times. XXXX is an abusive company. They are supposed to be protecting consumers. They need to be reigned in. they are causing me severe XXXX and stopping me from getting this job offer XXXX now XXXX XXXX  XXXX cant provide to my XXXXXXXX XXXX XXXX daughter PLEASE HELP ME PLEASE XXXX XXXX  now.with no help.\n",
            "4. On XX/XX/XXXX, I recieved a report from XXXX XXXX XXXX XXXX XXXX, XXXX, MD XXXX XXXX ) XXXX, which indicated a closed account from XXXX  XXXX auto opened in XX/XX/XXXX, but was removed from my credit report in XXXX, due to being older than 7 years I recieved this credit alert from equifax, XXXX in XXXX that it fell off my credit report. on XX/XX/XXXX, I see it's been placed back on my credit report in XX/XX/XXXX by this agency and when I logged in to see Equifax credit report and look at my closed accounts, XXXX  XXXX shows ( Closed Account ) but it's there to view and it's been there for XXXX  year and XXXX  months, so my complaint is why is it there it shouldn't even show, for XXXX  years XXXX months they've had this on my report, I want it removed because eventhough these account show closed, they are still sending out old information that should not be reported. This is causing me to pay more and keeping my credit score down, please enforce this and make them remove any and all closed accounts. Their disclaimer even states that these accounts are removed after 7 years, it's been XXXX, they should remove all of those closed accounts that way this will not happen again, and I'm asking that they be sued because this keeps certain groups of people credit scores down and that's discrimination, its also fraudulent because on one hand their telling us that this information is not being reported it's closed yet it shows up, so they are lying.\n",
            "5. -In XX/XX/XXXX, I was sent a notice to my address in Michigan by XXXX XXXX XXXX XXXX XXXX that my debt ( collected after having to live off my card due to house and joblessness ) had been sold to Portfolio Recovery Associates , LLC for {$2200.00}. As I had already moved to Florida, this letter was not forwarded to me in a timely manner. At this time, it showed up on my credit report as a collection debt. \n",
            "\n",
            "-Once I had obtained the supplemental information provided by Portfolio Recovery Associates LLC as proof of veracity of claim after disputing the collection, I was able to see the aforementioned notice, as well as a statement from Portfolio Recovery Associates containing my account number, the ( now corrected after an updated credit report request by them ) Florida address it was sent to, amount owed, contact information, etc. When I contacted Portfolio Recovery Associates, I was told they could not give me any further information because it had been transferred to be litigated. \n",
            "\n",
            "-Three years to the day XXXX XX/XX/XXXX XXXX and two states later, apparently a lawsuit was filed against me in an attempt to collect the debt. I was never served a summons. Once I found out about and looked up the case, I saw they had the correct address but an incorrect name, one that was corrected with the credit bureaus two months after said debt was sold to PRA. Thus, the notice of 'summons returned served ' in the court review is incorrect. Once I learned of the suit, I submitted the necessary paper work on my behalf. After that, I didn't hear from them, nor did an updated search return anything. \n",
            "\n",
            "-In XXXX of this year, I received a notice from the XXXX XXXX XXXX XXXX XXXX stating that the case was to be closed in a month due to lack of prosecution if no action takes place before then. Just before that dead line, the attorneys for PRA XXXX XXXX XXXX XXXX XXXX filed a motion to transfer the case to XXXX XXXX, citing that this was where they ( in fact did not ) serve the original summons. Once this was granted, they received a letter from the Clerk of Court stating they had 30 days to pay the transfer fees or the case would be dismissed. Two days before that due date, they submitted payment at the last minute. As of yet, I have not seen nor received anything from the XXXX XXXX XXXX XXXX regarding the matter.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The plain English request we will make of PaLM 2\n",
        "prompt = (\n",
        "    \"Please highlight the most obvious difference between\"\n",
        "    \"the two lists of comments:\\n\" + prompt1 + prompt2\n",
        ")\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mL5P0_3X04dE"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Query job 67a85808-9741-4ffa-9ac5-677a558bb5d7 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bigframes-dev&j=bq:US:67a85808-9741-4ffa-9ac5-677a558bb5d7&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from bigframes.ml.llm import PaLM2TextGenerator\n",
        "\n",
        "q_a_model = PaLM2TextGenerator(connection_name=\"bigframes-dev.us.bigframes-ml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ICWHsqAW1FNk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/google/home/henryjsolberg/bq/src/bigframes/venv/lib/python3.9/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if _pandas_api.is_sparse(col):\n"
          ]
        }
      ],
      "source": [
        "# Make a DataFrame containing only a single row with our prompt for PaLM 2\n",
        "df = bpd.DataFrame({\"prompt\": [prompt]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gB7e1LXU1pst"
      },
      "outputs": [
        {
          "ename": "BadRequest",
          "evalue": "400 POST https://bigquery.googleapis.com/bigquery/v2/projects/bigframes-dev/jobs?prettyPrint=false: Syntax error: Unclosed string literal at [5:104]\n\nLocation: us\nJob ID: 9b28df64-af3c-4dcc-b679-4300c3deab88\n [{'@type': 'type.googleapis.com/google.rpc.DebugInfo', 'detail': '[INVALID_INPUT] message=QUERY_ERROR: [Syntax error: Unclosed string literal at [5:104]] errorProto=code: \"QUERY_ERROR\"\\nargument: \"Syntax error: Unclosed string literal at [5:104]\"\\nlocation_type: OTHER\\nlocation: \"query\"\\n\\n\\tat com.google.cloud.helix.common.Exceptions.fromProto(Exceptions.java:2072)\\n\\tat com.google.cloud.helix.server.job.DremelErrorUtil.checkStatusWithDremelDetails(DremelErrorUtil.java:162)\\n\\tat com.google.cloud.helix.server.job.GoogleSqlQueryTransformer.parseQueryUncached(GoogleSqlQueryTransformer.java:527)\\n\\tat com.google.cloud.helix.server.job.GoogleSqlQueryTransformer.parseQuery(GoogleSqlQueryTransformer.java:511)\\n\\tat com.google.cloud.helix.server.job.GoogleSqlQueryTransformer.validateQuery(GoogleSqlQueryTransformer.java:251)\\n\\tat com.google.cloud.helix.server.job.LocalQueryJobController.checkQuery(LocalQueryJobController.java:4331)\\n\\tat com.google.cloud.helix.server.job.LocalQueryJobController.checkInternal(LocalQueryJobController.java:4461)\\n\\tat com.google.cloud.helix.server.job.LocalQueryJobController.checkAsync(LocalQueryJobController.java:4415)\\n\\tat com.google.cloud.helix.server.job.LocalSqlJobController.checkAsync(LocalSqlJobController.java:125)\\n\\tat com.google.cloud.helix.server.job.LocalJobController.check(LocalJobController.java:1247)\\n\\tat com.google.cloud.helix.server.job.JobControllerModule$1.check(JobControllerModule.java:461)\\n\\tat com.google.cloud.helix.server.job.JobStateMachine$1.check(JobStateMachine.java:3585)\\n\\tat com.google.cloud.helix.server.job.JobStateMachine.dryRunJob(JobStateMachine.java:2515)\\n\\tat com.google.cloud.helix.server.job.JobStateMachine.execute(JobStateMachine.java:2494)\\n\\tat com.google.cloud.helix.server.job.ApiJobStateChanger.execute(ApiJobStateChanger.java:33)\\n\\tat com.google.cloud.helix.server.job.rosy.HelixJobRosy.insertNormalizedJob(HelixJobRosy.java:1998)\\n\\tat com.google.cloud.helix.server.job.rosy.HelixJobRosy.insertJobInternal(HelixJobRosy.java:2467)\\n\\tat com.google.cloud.helix.server.job.rosy.HelixJobRosy.insertInternal(HelixJobRosy.java:2492)\\n\\tat com.google.cloud.helix.server.job.rosy.HelixJobRosy.insertRequestInternal(HelixJobRosy.java:3918)\\n\\tat com.google.cloud.helix.server.job.rosy.HelixJobRosy.insert(HelixJobRosy.java:3892)\\n\\tat jdk.internal.reflect.GeneratedMethodAccessor305.invoke(Unknown Source)\\n\\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\\n\\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$innerContinuation$3(RpcRequestProxy.java:435)\\n\\tat com.google.cloud.helix.common.rosy.RosyRequestDapperHookFactory$TracingRequestHook.call(RosyRequestDapperHookFactory.java:88)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$makeContinuation$4(RpcRequestProxy.java:461)\\n\\tat com.google.cloud.helix.common.rosy.RosyRequestCredsHookFactory$1.call(RosyRequestCredsHookFactory.java:56)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$makeContinuation$4(RpcRequestProxy.java:461)\\n\\tat com.google.cloud.helix.common.rosy.RosyRequestConcurrentCallsHookFactory$Hook.call(RosyRequestConcurrentCallsHookFactory.java:101)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$makeContinuation$4(RpcRequestProxy.java:461)\\n\\tat com.google.cloud.helix.common.rosy.RosyRequestVarzHookFactory$Hook.call(RosyRequestVarzHookFactory.java:464)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$makeContinuation$4(RpcRequestProxy.java:461)\\n\\tat com.google.cloud.helix.server.rosy.RosyRequestAuditHookFactory$1.call(RosyRequestAuditHookFactory.java:110)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$makeContinuation$4(RpcRequestProxy.java:461)\\n\\tat com.google.cloud.helix.common.rosy.RequestSecurityExtensionForGwsHookFactory$1.call(RequestSecurityExtensionForGwsHookFactory.java:69)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$makeContinuation$4(RpcRequestProxy.java:461)\\n\\tat com.google.cloud.helix.common.rosy.RosyRequestSecurityContextHookFactory$1.call(RosyRequestSecurityContextHookFactory.java:80)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$makeContinuation$4(RpcRequestProxy.java:461)\\n\\tat com.google.cloud.helix.server.rosy.RosyRequestContextHookFactory.call(RosyRequestContextHookFactory.java:58)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$makeContinuation$4(RpcRequestProxy.java:461)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.invoke(RpcRequestProxy.java:666)\\n\\tat com.sun.proxy.$Proxy52.insert(Unknown Source)\\n\\tat com.google.cloud.helix.proto.proto2api.HelixJobService$ServiceParameters$1.handleRequest(HelixJobService.java:917)\\n\\tat com.google.net.rpc3.impl.server.RpcServerInterceptor2Util$RpcApplicationHandlerAdaptor.handleRequest(RpcServerInterceptor2Util.java:82)\\n\\tat com.google.net.rpc3.impl.server.AggregatedRpcServerInterceptors.interceptRpc(AggregatedRpcServerInterceptors.java:97)\\n\\tat com.google.net.rpc3.impl.server.RpcServerInterceptor2Util$InterceptedApplicationHandlerImpl.handleRequest(RpcServerInterceptor2Util.java:67)\\n\\tat com.google.net.rpc3.impl.server.RpcServerInternalContext.runRpcInApplicationWithCancellation(RpcServerInternalContext.java:686)\\n\\tat com.google.net.rpc3.impl.server.RpcServerInternalContext.lambda$runRpcInApplication$0(RpcServerInternalContext.java:651)\\n\\tat io.grpc.Context.run(Context.java:536)\\n\\tat com.google.net.rpc3.impl.server.RpcServerInternalContext.runRpcInApplication(RpcServerInternalContext.java:651)\\n\\tat com.google.net.rpc3.util.RpcInProcessConnector$ServerInternalContext.lambda$runWithExecutor$1(RpcInProcessConnector.java:1964)\\n\\tat com.google.common.context.ContextRunnable.runInContext(ContextRunnable.java:83)\\n\\tat io.grpc.Context.run(Context.java:536)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContext(GenericContextCallback.java:75)\\n\\tat com.google.common.context.ContextRunnable.run(ContextRunnable.java:74)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\\n\\tat java.base/java.lang.Thread.run(Unknown Source)\\n\\tSuppressed: java.lang.Exception: Including call stack from HelixFutures\\n\\t\\tat com.google.cloud.helix.common.HelixFutures.getHelixException(HelixFutures.java:76)\\n\\t\\tat com.google.cloud.helix.common.HelixFutures.get(HelixFutures.java:42)\\n\\t\\tat com.google.cloud.helix.server.job.JobStateMachine.dryRunJob(JobStateMachine.java:2514)\\n\\t\\t... 45 more\\n\\tSuppressed: java.lang.Exception: Including call stack from HelixFutures\\n\\t\\tat com.google.cloud.helix.common.HelixFutures.getHelixException(HelixFutures.java:76)\\n\\t\\tat com.google.cloud.helix.common.HelixFutures.get(HelixFutures.java:42)\\n\\t\\t... 41 more\\n'}]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m major_difference \u001b[39m=\u001b[39m q_a_model\u001b[39m.\u001b[39;49mpredict(df)\n\u001b[1;32m      2\u001b[0m major_difference\n\u001b[1;32m      3\u001b[0m \u001b[39m#major_difference[\"ml_generate_text_llm_result\"].iloc[0]\u001b[39;00m\n",
            "File \u001b[0;32m~/bq/src/bigframes/bigframes/ml/llm.py:178\u001b[0m, in \u001b[0;36mPaLM2TextGenerator.predict\u001b[0;34m(self, X, temperature, max_output_tokens, top_k, top_p)\u001b[0m\n\u001b[1;32m    169\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{col_label: \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m    171\u001b[0m options \u001b[39m=\u001b[39m {\n\u001b[1;32m    172\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtemperature\u001b[39m\u001b[39m\"\u001b[39m: temperature,\n\u001b[1;32m    173\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmax_output_tokens\u001b[39m\u001b[39m\"\u001b[39m: max_output_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mflatten_json_output\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    177\u001b[0m }\n\u001b[0;32m--> 178\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bqml_model\u001b[39m.\u001b[39;49mgenerate_text(X, options)\n\u001b[1;32m    179\u001b[0m \u001b[39mreturn\u001b[39;00m cast(\n\u001b[1;32m    180\u001b[0m     bpd\u001b[39m.\u001b[39mDataFrame,\n\u001b[1;32m    181\u001b[0m     df[[_TEXT_GENERATE_RESULT_COLUMN]],\n\u001b[1;32m    182\u001b[0m )\n",
            "File \u001b[0;32m~/bq/src/bigframes/bigframes/ml/core.py:105\u001b[0m, in \u001b[0;36mBqmlModel.generate_text\u001b[0;34m(self, input_data, options)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_text\u001b[39m(\n\u001b[1;32m    100\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    101\u001b[0m     input_data: bpd\u001b[39m.\u001b[39mDataFrame,\n\u001b[1;32m    102\u001b[0m     options: Mapping[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mfloat\u001b[39m],\n\u001b[1;32m    103\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m bpd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m    104\u001b[0m     \u001b[39m# TODO: validate input data schema\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_sql(\n\u001b[1;32m    106\u001b[0m         input_data,\n\u001b[1;32m    107\u001b[0m         \u001b[39mlambda\u001b[39;49;00m source_df: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model_manipulation_sql_generator\u001b[39m.\u001b[39;49mml_generate_text(\n\u001b[1;32m    108\u001b[0m             source_df\u001b[39m=\u001b[39;49msource_df,\n\u001b[1;32m    109\u001b[0m             struct_options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    110\u001b[0m         ),\n\u001b[1;32m    111\u001b[0m     )\n",
            "File \u001b[0;32m~/bq/src/bigframes/bigframes/ml/core.py:80\u001b[0m, in \u001b[0;36mBqmlModel._apply_sql\u001b[0;34m(self, input_data, func)\u001b[0m\n\u001b[1;32m     77\u001b[0m _, index_col_ids, index_labels \u001b[39m=\u001b[39m input_data\u001b[39m.\u001b[39m_to_sql_query(include_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     79\u001b[0m sql \u001b[39m=\u001b[39m func(input_data)\n\u001b[0;32m---> 80\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49mread_gbq(sql, index_col\u001b[39m=\u001b[39;49mindex_col_ids)\n\u001b[1;32m     81\u001b[0m df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mnames \u001b[39m=\u001b[39m index_labels\n\u001b[1;32m     83\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
            "File \u001b[0;32m~/bq/src/bigframes/bigframes/session/__init__.py:290\u001b[0m, in \u001b[0;36mSession.read_gbq\u001b[0;34m(self, query_or_table, index_col, col_order, max_results)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_gbq\u001b[39m(\n\u001b[1;32m    280\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    281\u001b[0m     query_or_table: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m dataframe\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m    288\u001b[0m     \u001b[39m# TODO(b/281571214): Generate prompt to show the progress of read_gbq.\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[39mif\u001b[39;00m _is_query(query_or_table):\n\u001b[0;32m--> 290\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_gbq_query(\n\u001b[1;32m    291\u001b[0m             query_or_table,\n\u001b[1;32m    292\u001b[0m             index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m    293\u001b[0m             col_order\u001b[39m=\u001b[39;49mcol_order,\n\u001b[1;32m    294\u001b[0m             max_results\u001b[39m=\u001b[39;49mmax_results,\n\u001b[1;32m    295\u001b[0m             api_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mread_gbq\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    296\u001b[0m         )\n\u001b[1;32m    297\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m         \u001b[39m# TODO(swast): Query the snapshot table but mark it as a\u001b[39;00m\n\u001b[1;32m    299\u001b[0m         \u001b[39m# deterministic query so we can avoid serializing if we have a\u001b[39;00m\n\u001b[1;32m    300\u001b[0m         \u001b[39m# unique index.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_gbq_table(\n\u001b[1;32m    302\u001b[0m             query_or_table,\n\u001b[1;32m    303\u001b[0m             index_col\u001b[39m=\u001b[39mindex_col,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m             api_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mread_gbq\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    307\u001b[0m         )\n",
            "File \u001b[0;32m~/bq/src/bigframes/bigframes/session/__init__.py:432\u001b[0m, in \u001b[0;36mSession._read_gbq_query\u001b[0;34m(self, query, index_col, col_order, max_results, api_name)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    430\u001b[0m     index_cols \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(index_col)\n\u001b[0;32m--> 432\u001b[0m destination, query_job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query_to_destination(\n\u001b[1;32m    433\u001b[0m     query,\n\u001b[1;32m    434\u001b[0m     index_cols,\n\u001b[1;32m    435\u001b[0m     api_name\u001b[39m=\u001b[39;49mapi_name,\n\u001b[1;32m    436\u001b[0m )\n\u001b[1;32m    438\u001b[0m \u001b[39m# If there was no destination table, that means the query must have\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[39m# been DDL or DML. Return some job metadata, instead.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m destination:\n",
            "File \u001b[0;32m~/bq/src/bigframes/bigframes/session/__init__.py:319\u001b[0m, in \u001b[0;36mSession._query_to_destination\u001b[0;34m(self, query, index_cols, api_name)\u001b[0m\n\u001b[1;32m    317\u001b[0m dry_run_config \u001b[39m=\u001b[39m bigquery\u001b[39m.\u001b[39mQueryJobConfig()\n\u001b[1;32m    318\u001b[0m dry_run_config\u001b[39m.\u001b[39mdry_run \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m _, dry_run_job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_start_query(query, job_config\u001b[39m=\u001b[39;49mdry_run_config)\n\u001b[1;32m    320\u001b[0m \u001b[39mif\u001b[39;00m dry_run_job\u001b[39m.\u001b[39mstatement_type \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSELECT\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    321\u001b[0m     _, query_job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_query(query)\n",
            "File \u001b[0;32m~/bq/src/bigframes/bigframes/session/__init__.py:1523\u001b[0m, in \u001b[0;36mSession._start_query\u001b[0;34m(self, sql, job_config, max_results)\u001b[0m\n\u001b[1;32m   1519\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1520\u001b[0m \u001b[39mStarts query job and waits for results.\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m job_config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_job_config(job_config)\n\u001b[0;32m-> 1523\u001b[0m query_job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbqclient\u001b[39m.\u001b[39;49mquery(sql, job_config\u001b[39m=\u001b[39;49mjob_config)\n\u001b[1;32m   1525\u001b[0m opts \u001b[39m=\u001b[39m bigframes\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mdisplay\n\u001b[1;32m   1526\u001b[0m \u001b[39mif\u001b[39;00m opts\u001b[39m.\u001b[39mprogress_bar \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m query_job\u001b[39m.\u001b[39mconfiguration\u001b[39m.\u001b[39mdry_run:\n",
            "File \u001b[0;32m~/bq/src/bigframes/venv/lib/python3.9/site-packages/google/cloud/bigquery/client.py:3403\u001b[0m, in \u001b[0;36mClient.query\u001b[0;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry, api_method)\u001b[0m\n\u001b[1;32m   3392\u001b[0m     \u001b[39mreturn\u001b[39;00m _job_helpers\u001b[39m.\u001b[39mquery_jobs_query(\n\u001b[1;32m   3393\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   3394\u001b[0m         query,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3400\u001b[0m         job_retry,\n\u001b[1;32m   3401\u001b[0m     )\n\u001b[1;32m   3402\u001b[0m \u001b[39melif\u001b[39;00m api_method \u001b[39m==\u001b[39m enums\u001b[39m.\u001b[39mQueryApiMethod\u001b[39m.\u001b[39mINSERT:\n\u001b[0;32m-> 3403\u001b[0m     \u001b[39mreturn\u001b[39;00m _job_helpers\u001b[39m.\u001b[39;49mquery_jobs_insert(\n\u001b[1;32m   3404\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   3405\u001b[0m         query,\n\u001b[1;32m   3406\u001b[0m         job_config,\n\u001b[1;32m   3407\u001b[0m         job_id,\n\u001b[1;32m   3408\u001b[0m         job_id_prefix,\n\u001b[1;32m   3409\u001b[0m         location,\n\u001b[1;32m   3410\u001b[0m         project,\n\u001b[1;32m   3411\u001b[0m         retry,\n\u001b[1;32m   3412\u001b[0m         timeout,\n\u001b[1;32m   3413\u001b[0m         job_retry,\n\u001b[1;32m   3414\u001b[0m     )\n\u001b[1;32m   3415\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3416\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot unexpected value for api_method: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(api_method)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/bq/src/bigframes/venv/lib/python3.9/site-packages/google/cloud/bigquery/_job_helpers.py:114\u001b[0m, in \u001b[0;36mquery_jobs_insert\u001b[0;34m(client, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m         \u001b[39mreturn\u001b[39;00m query_job\n\u001b[0;32m--> 114\u001b[0m future \u001b[39m=\u001b[39m do_query()\n\u001b[1;32m    115\u001b[0m \u001b[39m# The future might be in a failed state now, but if it's\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m# unrecoverable, we'll find out when we ask for it's result, at which\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m# point, we may retry.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m job_id_given:\n",
            "File \u001b[0;32m~/bq/src/bigframes/venv/lib/python3.9/site-packages/google/cloud/bigquery/_job_helpers.py:91\u001b[0m, in \u001b[0;36mquery_jobs_insert.<locals>.do_query\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m query_job \u001b[39m=\u001b[39m job\u001b[39m.\u001b[39mQueryJob(job_ref, query, client\u001b[39m=\u001b[39mclient, job_config\u001b[39m=\u001b[39mjob_config)\n\u001b[1;32m     90\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     query_job\u001b[39m.\u001b[39;49m_begin(retry\u001b[39m=\u001b[39;49mretry, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m     92\u001b[0m \u001b[39mexcept\u001b[39;00m core_exceptions\u001b[39m.\u001b[39mConflict \u001b[39mas\u001b[39;00m create_exc:\n\u001b[1;32m     93\u001b[0m     \u001b[39m# The thought is if someone is providing their own job IDs and they get\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[39m# their job ID generation wrong, this could end up returning results for\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[39m# the wrong query. We thus only try to recover if job ID was not given.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[39mif\u001b[39;00m job_id_given:\n",
            "File \u001b[0;32m~/bq/src/bigframes/venv/lib/python3.9/site-packages/google/cloud/bigquery/job/query.py:1310\u001b[0m, in \u001b[0;36mQueryJob._begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"API call:  begin the job via a POST request\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m \n\u001b[1;32m   1292\u001b[0m \u001b[39mSee\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1306\u001b[0m \u001b[39m    ValueError: If the job has already begun.\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1310\u001b[0m     \u001b[39msuper\u001b[39;49m(QueryJob, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_begin(client\u001b[39m=\u001b[39;49mclient, retry\u001b[39m=\u001b[39;49mretry, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1311\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mGoogleAPICallError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m   1312\u001b[0m     exc\u001b[39m.\u001b[39mmessage \u001b[39m=\u001b[39m _EXCEPTION_FOOTER_TEMPLATE\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1313\u001b[0m         message\u001b[39m=\u001b[39mexc\u001b[39m.\u001b[39mmessage, location\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocation, job_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjob_id\n\u001b[1;32m   1314\u001b[0m     )\n",
            "File \u001b[0;32m~/bq/src/bigframes/venv/lib/python3.9/site-packages/google/cloud/bigquery/job/base.py:693\u001b[0m, in \u001b[0;36m_AsyncJob._begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39m# jobs.insert is idempotent because we ensure that every new\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[39m# job has an ID.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m span_attributes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m\"\u001b[39m: path}\n\u001b[0;32m--> 693\u001b[0m api_response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49m_call_api(\n\u001b[1;32m    694\u001b[0m     retry,\n\u001b[1;32m    695\u001b[0m     span_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mBigQuery.job.begin\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    696\u001b[0m     span_attributes\u001b[39m=\u001b[39;49mspan_attributes,\n\u001b[1;32m    697\u001b[0m     job_ref\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    698\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    699\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m    700\u001b[0m     data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto_api_repr(),\n\u001b[1;32m    701\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    702\u001b[0m )\n\u001b[1;32m    703\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_properties(api_response)\n",
            "File \u001b[0;32m~/bq/src/bigframes/venv/lib/python3.9/site-packages/google/cloud/bigquery/client.py:813\u001b[0m, in \u001b[0;36mClient._call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[39mif\u001b[39;00m span_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    810\u001b[0m     \u001b[39mwith\u001b[39;00m create_span(\n\u001b[1;32m    811\u001b[0m         name\u001b[39m=\u001b[39mspan_name, attributes\u001b[39m=\u001b[39mspan_attributes, client\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, job_ref\u001b[39m=\u001b[39mjob_ref\n\u001b[1;32m    812\u001b[0m     ):\n\u001b[0;32m--> 813\u001b[0m         \u001b[39mreturn\u001b[39;00m call()\n\u001b[1;32m    815\u001b[0m \u001b[39mreturn\u001b[39;00m call()\n",
            "File \u001b[0;32m~/bq/src/bigframes/venv/lib/python3.9/site-packages/google/api_core/retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m target \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    346\u001b[0m sleep_generator \u001b[39m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    347\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maximum, multiplier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiplier\n\u001b[1;32m    348\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[39mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    350\u001b[0m     target,\n\u001b[1;32m    351\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predicate,\n\u001b[1;32m    352\u001b[0m     sleep_generator,\n\u001b[1;32m    353\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_timeout,\n\u001b[1;32m    354\u001b[0m     on_error\u001b[39m=\u001b[39;49mon_error,\n\u001b[1;32m    355\u001b[0m )\n",
            "File \u001b[0;32m~/bq/src/bigframes/venv/lib/python3.9/site-packages/google/api_core/retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mfor\u001b[39;00m sleep \u001b[39min\u001b[39;00m sleep_generator:\n\u001b[1;32m    190\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[39mreturn\u001b[39;00m target()\n\u001b[1;32m    193\u001b[0m     \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[39m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
            "File \u001b[0;32m~/bq/src/bigframes/venv/lib/python3.9/site-packages/google/cloud/_http/__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    482\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(\n\u001b[1;32m    483\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[1;32m    484\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m     extra_api_info\u001b[39m=\u001b[39mextra_api_info,\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus_code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 494\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_http_response(response)\n\u001b[1;32m    496\u001b[0m \u001b[39mif\u001b[39;00m expect_json \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mcontent:\n\u001b[1;32m    497\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mjson()\n",
            "\u001b[0;31mBadRequest\u001b[0m: 400 POST https://bigquery.googleapis.com/bigquery/v2/projects/bigframes-dev/jobs?prettyPrint=false: Syntax error: Unclosed string literal at [5:104]\n\nLocation: us\nJob ID: 9b28df64-af3c-4dcc-b679-4300c3deab88\n [{'@type': 'type.googleapis.com/google.rpc.DebugInfo', 'detail': '[INVALID_INPUT] message=QUERY_ERROR: [Syntax error: Unclosed string literal at [5:104]] errorProto=code: \"QUERY_ERROR\"\\nargument: \"Syntax error: Unclosed string literal at [5:104]\"\\nlocation_type: OTHER\\nlocation: \"query\"\\n\\n\\tat com.google.cloud.helix.common.Exceptions.fromProto(Exceptions.java:2072)\\n\\tat com.google.cloud.helix.server.job.DremelErrorUtil.checkStatusWithDremelDetails(DremelErrorUtil.java:162)\\n\\tat com.google.cloud.helix.server.job.GoogleSqlQueryTransformer.parseQueryUncached(GoogleSqlQueryTransformer.java:527)\\n\\tat com.google.cloud.helix.server.job.GoogleSqlQueryTransformer.parseQuery(GoogleSqlQueryTransformer.java:511)\\n\\tat com.google.cloud.helix.server.job.GoogleSqlQueryTransformer.validateQuery(GoogleSqlQueryTransformer.java:251)\\n\\tat com.google.cloud.helix.server.job.LocalQueryJobController.checkQuery(LocalQueryJobController.java:4331)\\n\\tat com.google.cloud.helix.server.job.LocalQueryJobController.checkInternal(LocalQueryJobController.java:4461)\\n\\tat com.google.cloud.helix.server.job.LocalQueryJobController.checkAsync(LocalQueryJobController.java:4415)\\n\\tat com.google.cloud.helix.server.job.LocalSqlJobController.checkAsync(LocalSqlJobController.java:125)\\n\\tat com.google.cloud.helix.server.job.LocalJobController.check(LocalJobController.java:1247)\\n\\tat com.google.cloud.helix.server.job.JobControllerModule$1.check(JobControllerModule.java:461)\\n\\tat com.google.cloud.helix.server.job.JobStateMachine$1.check(JobStateMachine.java:3585)\\n\\tat com.google.cloud.helix.server.job.JobStateMachine.dryRunJob(JobStateMachine.java:2515)\\n\\tat com.google.cloud.helix.server.job.JobStateMachine.execute(JobStateMachine.java:2494)\\n\\tat com.google.cloud.helix.server.job.ApiJobStateChanger.execute(ApiJobStateChanger.java:33)\\n\\tat com.google.cloud.helix.server.job.rosy.HelixJobRosy.insertNormalizedJob(HelixJobRosy.java:1998)\\n\\tat com.google.cloud.helix.server.job.rosy.HelixJobRosy.insertJobInternal(HelixJobRosy.java:2467)\\n\\tat com.google.cloud.helix.server.job.rosy.HelixJobRosy.insertInternal(HelixJobRosy.java:2492)\\n\\tat com.google.cloud.helix.server.job.rosy.HelixJobRosy.insertRequestInternal(HelixJobRosy.java:3918)\\n\\tat com.google.cloud.helix.server.job.rosy.HelixJobRosy.insert(HelixJobRosy.java:3892)\\n\\tat jdk.internal.reflect.GeneratedMethodAccessor305.invoke(Unknown Source)\\n\\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\\n\\tat java.base/java.lang.reflect.Method.invoke(Unknown Source)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$innerContinuation$3(RpcRequestProxy.java:435)\\n\\tat com.google.cloud.helix.common.rosy.RosyRequestDapperHookFactory$TracingRequestHook.call(RosyRequestDapperHookFactory.java:88)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$makeContinuation$4(RpcRequestProxy.java:461)\\n\\tat com.google.cloud.helix.common.rosy.RosyRequestCredsHookFactory$1.call(RosyRequestCredsHookFactory.java:56)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$makeContinuation$4(RpcRequestProxy.java:461)\\n\\tat com.google.cloud.helix.common.rosy.RosyRequestConcurrentCallsHookFactory$Hook.call(RosyRequestConcurrentCallsHookFactory.java:101)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$makeContinuation$4(RpcRequestProxy.java:461)\\n\\tat com.google.cloud.helix.common.rosy.RosyRequestVarzHookFactory$Hook.call(RosyRequestVarzHookFactory.java:464)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$makeContinuation$4(RpcRequestProxy.java:461)\\n\\tat com.google.cloud.helix.server.rosy.RosyRequestAuditHookFactory$1.call(RosyRequestAuditHookFactory.java:110)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$makeContinuation$4(RpcRequestProxy.java:461)\\n\\tat com.google.cloud.helix.common.rosy.RequestSecurityExtensionForGwsHookFactory$1.call(RequestSecurityExtensionForGwsHookFactory.java:69)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$makeContinuation$4(RpcRequestProxy.java:461)\\n\\tat com.google.cloud.helix.common.rosy.RosyRequestSecurityContextHookFactory$1.call(RosyRequestSecurityContextHookFactory.java:80)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$makeContinuation$4(RpcRequestProxy.java:461)\\n\\tat com.google.cloud.helix.server.rosy.RosyRequestContextHookFactory.call(RosyRequestContextHookFactory.java:58)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.lambda$makeContinuation$4(RpcRequestProxy.java:461)\\n\\tat com.google.cloud.helix.common.rosy.RpcRequestProxy.invoke(RpcRequestProxy.java:666)\\n\\tat com.sun.proxy.$Proxy52.insert(Unknown Source)\\n\\tat com.google.cloud.helix.proto.proto2api.HelixJobService$ServiceParameters$1.handleRequest(HelixJobService.java:917)\\n\\tat com.google.net.rpc3.impl.server.RpcServerInterceptor2Util$RpcApplicationHandlerAdaptor.handleRequest(RpcServerInterceptor2Util.java:82)\\n\\tat com.google.net.rpc3.impl.server.AggregatedRpcServerInterceptors.interceptRpc(AggregatedRpcServerInterceptors.java:97)\\n\\tat com.google.net.rpc3.impl.server.RpcServerInterceptor2Util$InterceptedApplicationHandlerImpl.handleRequest(RpcServerInterceptor2Util.java:67)\\n\\tat com.google.net.rpc3.impl.server.RpcServerInternalContext.runRpcInApplicationWithCancellation(RpcServerInternalContext.java:686)\\n\\tat com.google.net.rpc3.impl.server.RpcServerInternalContext.lambda$runRpcInApplication$0(RpcServerInternalContext.java:651)\\n\\tat io.grpc.Context.run(Context.java:536)\\n\\tat com.google.net.rpc3.impl.server.RpcServerInternalContext.runRpcInApplication(RpcServerInternalContext.java:651)\\n\\tat com.google.net.rpc3.util.RpcInProcessConnector$ServerInternalContext.lambda$runWithExecutor$1(RpcInProcessConnector.java:1964)\\n\\tat com.google.common.context.ContextRunnable.runInContext(ContextRunnable.java:83)\\n\\tat io.grpc.Context.run(Context.java:536)\\n\\tat com.google.tracing.GenericContextCallback.runInInheritedContext(GenericContextCallback.java:75)\\n\\tat com.google.common.context.ContextRunnable.run(ContextRunnable.java:74)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\\n\\tat java.base/java.lang.Thread.run(Unknown Source)\\n\\tSuppressed: java.lang.Exception: Including call stack from HelixFutures\\n\\t\\tat com.google.cloud.helix.common.HelixFutures.getHelixException(HelixFutures.java:76)\\n\\t\\tat com.google.cloud.helix.common.HelixFutures.get(HelixFutures.java:42)\\n\\t\\tat com.google.cloud.helix.server.job.JobStateMachine.dryRunJob(JobStateMachine.java:2514)\\n\\t\\t... 45 more\\n\\tSuppressed: java.lang.Exception: Including call stack from HelixFutures\\n\\t\\tat com.google.cloud.helix.common.HelixFutures.getHelixException(HelixFutures.java:76)\\n\\t\\tat com.google.cloud.helix.common.HelixFutures.get(HelixFutures.java:42)\\n\\t\\t... 41 more\\n'}]"
          ]
        }
      ],
      "source": [
        "# Send the request for PaLM 2 to generate a response to our prompt\n",
        "major_difference = q_a_model.predict(df)\n",
        "# PaLM 2's response is the only row in the dataframe result \n",
        "major_difference[\"ml_generate_text_llm_result\"].iloc[0]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
